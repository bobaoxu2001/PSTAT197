# equivalent for loop
rslt_loop <- rep(NA, length(vals))
for(i in 1:length(vals)){
rslt_loop[i] <- 2*vals[i]
}
# compare
rbind(rslt_loop, rslt_apply)
# number of tests to perform
n_tests <- 100
# convert to a list
asd_list <- asd %>%
select(1:(n_tests + 1)) %>%
pivot_longer(cols = -group,
names_to = 'protein',
values_to = 'level') %>%
group_by(protein) %>%
group_split()
# first entry in list
asd_list[[1]]
t.test(level ~ group, data = asd_list[[1]])
# p value for ith protein
tt_fn <- function(i){
t.test(level ~ group, data = asd_list[[i]])$p.value
}
# check
tt_fn(1)
sapply(1:n_tests, tt_fn)
start <- Sys.time()
rslt <- sapply(1:n_tests, tt_fn)
end <- Sys.time()
end - start
start <- Sys.time()
n_tests <- 100
rslt <- tibble(protein = colnames(asd)[2:(n_tests + 1)],
p = NA)
for(i in 1:n_tests){
x <- asd %>% filter(group == 'ASD') %>% pull(i + 1)
y <- asd %>% filter(group == 'TD') %>% pull(i + 1)
rslt$p[i] <- t.test(x, y, var.equal = F)$p.value
}
end <- Sys.time()
end - start
tt_fn <- function(i){
test_rslt <- t.test(level ~ group, data = asd_list[[i]])
out <- c(pval = test_rslt$p.value,
tstat = test_rslt$statistic)
out
}
tt_fn(1)
sapply(1:5, tt_fn) %>% t() %>% as_tibble()
# apply a function to an index set
simple_fn_ix <- function(i){2*vals[i]}
rslt_apply <- sapply(1:length(vals), simple_fn_ix)
# equivalent for loop
rslt_loop <- rep(NA, length(vals))
for(i in 1:length(vals)){
rslt_loop[i] <- 2*vals[i]
}
# compare
rbind(rslt_loop, rslt_apply)
asd_nested <- asd %>%
pivot_longer(-group,
names_to = 'protein',
values_to = 'level') %>%
nest(data = c(level, group))
asd_nested %>% head(5)
asd_nested %>%
slice(1L) %>%
pull(data)
asd_nested %>%
slice(1L) %>%
pull(data)
tt_fn <- function(.df){
t.test(level ~ group, data = .df)
}
rslt <- asd_nested %>%
slice(1:10) %>%
mutate(ttest.out = map(data, tt_fn))
rslt
rslt %>% slice(1L) %>% pull(ttest.out)
asd_nested %>%
slice(1L) %>%
unnest(cols = data) %>%
infer::t_test(formula = level ~ group,
order = c('ASD', 'TD'),
alternative = 'two-sided',
var.equal = F)
rslt %>% slice(1L) %>% pull(ttest.out)
# wrapper around infer::t_test
tt_fn <- function(.df){
infer::t_test(.df,
formula = level ~ group,
order = c('ASD', 'TD'),
alternative = 'two-sided',
var.equal = F)
}
# compute test results
tt_out <- asd_nested %>%
slice(1:n_tests) %>%
mutate(ttest = map(data, tt_fn))
# preview
tt_out %>% head(4)
tt_out %>%
unnest(ttest) %>%
head(4)
# time it
start <- Sys.time()
tt_out <- asd_nested %>%
slice(1:n_tests) %>%
mutate(ttest = map(data, tt_fn))
end <- Sys.time()
end - start
# bonferroni correction
tt_out %>%
unnest(ttest) %>%
mutate(p_adj = p_value*n_tests) %>%
select(protein, p_value, p_adj) %>%
arrange(p_adj) %>%
head(4)
library(tidyverse)
# data location
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
# import
census <- read_csv(url,
col_names = c("age",
"workclass",
"fnlwgt",
"education",
"education_1",
"marital_status",
"occupation",
"relationship",
"race",
"sex",
"capital_gain",
"capital_loss",
"hours_per_week",
"native_country",
"income")) %>%
mutate(income = factor(income)) %>%
select(-fnlwgt, -education_1)
census %>% head(4)
# inspect repsonse
census %>% pull(income) %>% str()
# retrieve column names
possible_predictors <- census %>%
select(-income) %>%
colnames()
# grab 2 columns at random
predictors <- sample(possible_predictors,
size = 2,
replace = F)
# select these columns from the bootstrap sample
train <- census_boot %>%
select(c(income, any_of(predictors)))
# resample data
census_boot <- census %>%
sample_n(size = 200, replace = T)
# retrieve column names
possible_predictors <- census %>%
select(-income) %>%
colnames()
# grab 2 columns at random
predictors <- sample(possible_predictors,
size = 2,
replace = F)
# select these columns from the bootstrap sample
train <- census_boot %>%
select(c(income, any_of(predictors)))
# comment out -- don't overwrite your bootstrap sample!
census_boot <- census %>%
sample_n(size = 200, replace = T)
# for continuous variables
census_boot %>%
ggplot(aes(x = age, # replace with predictor name
y = income)) +
geom_jitter(height = 0.1) +
geom_vline(xintercept = 35) # adjust cutoff
census_boot %>%
ggplot(aes(x = age, # replace with predictor name
y = ..density..)) +
geom_density(aes(color = income, fill = income),
alpha = 0.5) +
geom_vline(xintercept = 35) # adjust cutoff
# for categorical variables
census_boot %>%
group_by(workclass, income) %>%
count() %>%
spread(income, n) %>%
mutate_all(~ replace_na(.x, 0)) %>%
mutate(high.inc = `<=50K` > `>50K`)
# pick out categories that are majority high income
highinc_categories <- census_boot %>%
group_by(workclass, # replace with predictor name
income) %>%
count() %>%
spread(income, n) %>%
mutate_all(~ replace_na(.x, 0)) %>%
mutate(high.inc = `<=50K` > `>50K`) %>%
filter(high.inc == T) %>%
pull(workclass) # replace with predictor name
library(tidyverse)
# data location
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
# import
census <- read_csv(url,
col_names = c("age",
"workclass",
"fnlwgt",
"education",
"education_1",
"marital_status",
"occupation",
"relationship",
"race",
"sex",
"capital_gain",
"capital_loss",
"hours_per_week",
"native_country",
"income")) %>%
mutate(income = factor(income)) %>%
select(-fnlwgt, -education_1)
census %>% head(4)
# inspect repsonse
census %>% pull(income) %>% str()
# resample data
census_boot <- census %>%
sample_n(size = 200, replace = T)
# retrieve column names
possible_predictors <- census %>%
select(-income) %>%
colnames()
# grab 2 columns at random
predictors <- sample(possible_predictors,
size = 2,
replace = F)
# select these columns from the bootstrap sample
train <- census_boot %>%
select(c(income, any_of(predictors)))
# retrieve column names
possible_predictors <- census %>%
select(-income) %>%
colnames()
# grab 2 columns at random
predictors <- sample(possible_predictors,
size = 2,
replace = F)
# select these columns from the bootstrap sample
train <- census_boot %>%
select(c(income, any_of(predictors)))
# retrieve column names
possible_predictors <- census %>%
select(-income) %>%
colnames()
# grab 2 columns at random
predictors <- sample(possible_predictors,
size = 2,
replace = F)
# select these columns from the bootstrap sample
train <- census_boot %>%
select(c(income, any_of(predictors)))
# retrieve column names
possible_predictors <- census %>%
select(-income) %>%
colnames()
# grab 2 columns at random
predictors <- sample(possible_predictors,
size = 2,
replace = F)
# select these columns from the bootstrap sample
train <- census_boot %>%
select(c(income, any_of(predictors)))
train
# comment out -- don't overwrite your bootstrap sample!
census_boot <- census %>%
sample_n(size = 200, replace = T)
# for continuous variables
census_boot %>%
ggplot(aes(x = occupation, # replace with predictor name
y = income)) +
geom_jitter(height = 0.1) +
geom_vline(xintercept = 35) # adjust cutoff
# comment out -- don't overwrite your bootstrap sample!
census_boot <- census %>%
sample_n(size = 200, replace = T)
# for continuous variables
census_boot %>%
ggplot(aes(x = hours_per_week, # replace with predictor name
y = income)) +
geom_jitter(height = 0.1) +
geom_vline(xintercept = 35) # adjust cutoff
census_boot %>%
ggplot(aes(x = hours_per_week, # replace with predictor name
y = ..density..)) +
geom_density(aes(color = income, fill = income),
alpha = 0.5) +
geom_vline(xintercept = 35) # adjust cutoff
# pick out categories that are majority high income
highinc_categories <- census_boot %>%
group_by(workclass, # replace with predictor name
income) %>%
count() %>%
spread(income, n) %>%
mutate_all(~ replace_na(.x, 0)) %>%
mutate(high.inc = `<=50K` > `>50K`) %>%
filter(high.inc == T) %>%
pull(workclass) # replace with predictor name
# for categorical variables
census_boot %>%
group_by(education, income) %>%
count() %>%
spread(income, n) %>%
mutate_all(~ replace_na(.x, 0)) %>%
mutate(high.inc = `<=50K` > `>50K`)
# pick out categories that are majority high income
highinc_categories <- census_boot %>%
group_by(education, # replace with predictor name
income) %>%
count() %>%
spread(income, n) %>%
mutate_all(~ replace_na(.x, 0)) %>%
mutate(high.inc = `<=50K` > `>50K`) %>%
filter(high.inc == T) %>%
pull(education) # replace with predictor name
# comment out -- don't overwrite your bootstrap sample!
census_boot <- census %>%
sample_n(size = 200, replace = T)
# for continuous variables
census_boot %>%
ggplot(aes(x = age, # replace with predictor name
y = income)) +
geom_jitter(height = 0.1) +
geom_vline(xintercept = 35) # adjust cutoff
# load packages
library(tidyverse)
library(tidymodels)
library(modelr)
library(rsample)
library(yardstick)
# read data
url <- 'https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/labs/lab4-logistic/data/biomarker_clean.csv'
s_star <- c("DERM", "RELT", "IgD", "PTN", "FSTL1")
biomarker <- read_csv(url) %>%
# subset to proteins of interest and group
select(group, any_of(s_star)) %>%
# convert group (chr) to binary (lgl)
mutate(class = (group == 'ASD')) %>%
select(-group)
# load packages
library(tidyverse)
library(tidymodels)
library(modelr)
library(rsample)
library(yardstick)
# read data
url <- 'https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/labs/lab4-logistic/data/biomarker_clean.csv'
s_star <- c("DERM", "RELT", "IgD", "PTN", "FSTL1")
biomarker <- read_csv(url) %>%
# subset to proteins of interest and group
select(group, any_of(s_star)) %>%
# convert group (chr) to binary (lgl)
mutate(class = (group == 'ASD')) %>%
select(-group)
# for reproducibility
set.seed(102022)
# partition data
partitions <- biomarker %>%
initial_split(prop = 0.8)
# examine
partitions
# training set
training(partitions) %>% head(4)
# testing set
testing(partitions) %>% head(4)
# fit glm
fit <- glm(class ~ .,
data = biomarker,
family = binomial(link = "logit"))
tidy(fit)
# compute predictions on the test set
testing(partitions) %>%
add_predictions(fit)
# manually transform to probabilities
testing(partitions) %>%
add_predictions(fit) %>%
mutate(probs = 1/(1 + exp(-pred))) %>%
select(class, pred, probs) %>%
head(5)
# predict on scale of response
testing(partitions) %>%
add_predictions(fit, type = 'response') %>%
select(class, pred) %>%
head(5)
# predict classes
testing(partitions) %>%
add_predictions(fit, type = 'response') %>%
mutate(pred.class = (pred > 0.5)) %>%
select(class, pred, pred.class) %>%
head(5)
# tabulate
testing(partitions) %>%
add_predictions(fit, type = 'response') %>%
mutate(pred.class = (pred > 0.5)) %>%
select(class, pred.class) %>%
table()
# store predictions as factors
pred_df <- testing(partitions) %>%
add_predictions(fit, type = 'response') %>%
mutate(pred.class = (pred > 0.5),
group = factor(class, labels = c('TD', 'ASD')),
pred.group = factor(pred.class, labels = c('TD', 'ASD')))
# check order of factor levels
pred_df %>% pull(group) %>% levels()
# compute specificity
pred_df %>%
specificity(truth = group,
estimate = pred.group,
event_level = 'second')
# sensitivity
pred_df %>%
sensitivity(truth = group,
estimate = pred.group,
event_level = 'second')
# define panel (arguments must be yardstick metric function names)
panel_fn <- metric_set(sensitivity, specificity)
# compute
pred_df %>%
panel_fn(truth = group,
estimate = pred.group,
event_level = 'second')
pred_df %>% conf_mat(truth = group, estimate = pred.group)
pred_df %>%
roc_curve(truth = group, estimate = pred)
pred_df %>%
roc_curve(truth = group,
estimate = pred,
event_level = 'second') %>%
ggplot(aes(y = sensitivity, x = 1 - specificity)) +
geom_path() +
geom_abline(slope = 1, intercept = 0)
pred_df %>% roc_auc(truth = group,
estimate = pred,
event_level = 'second')
panel <- metric_set(roc_auc, accuracy)
pred_df %>% panel(truth = group,
estimate = pred.group,
pred,
event_level = 'second')
# define some helper functions
fit_fn <- function(.df){
glm(class ~ ., family = 'binomial', data = .df)
}
pred_fn <- function(.df, .mdl){
.df %>% add_predictions(.mdl, type = 'response')
}
panel <- metric_set(sensitivity, specificity, accuracy, roc_auc)
eval_fn <- function(.df){
.df %>%
mutate(group = factor(class, labels = c('TD', 'ASD')),
pred.group = factor(pred > 0.5, labels = c('TD', 'ASD'))) %>%
panel(truth = group,
estimate = pred.group,
pred,
event_level = 'second')
}
set.seed(101922)
n_splits <- 400
out <- tibble(partition = 1:n_splits,
split = map(partition, ~ initial_split(biomarker, prop = 0.8)),
train = map(split, training),
test = map(split, testing),
fit = map(train, fit_fn),
pred_test = map2(test, fit, pred_fn),
pred_train = map2(train, fit, pred_fn),
eval_test = map(pred_test, eval_fn),
eval_train = map(pred_train, eval_fn))
out %>% head(4)
test_accuracy <- out %>%
select(partition, contains('eval')) %>%
unnest(eval_test) %>%
select(partition, .metric, .estimate) %>%
pivot_wider(names_from = .metric, values_from = .estimate)
train_accuracy <- out %>%
select(partition, contains('eval')) %>%
unnest(eval_train) %>%
select(partition, .metric, .estimate) %>%
pivot_wider(names_from = .metric, values_from = .estimate)
test_accuracy %>% head(4)
train_accuracy %>% head(4)
train_summaries <- train_accuracy %>%
rename(roc.auc = roc_auc) %>%
select(-partition) %>%
summarize_all(.funs = list(mean = mean, sd = sd)) %>%
gather() %>%
separate(key, into = c('metric', 'stat'), sep = '_') %>%
spread(stat, value)
test_summaries <- test_accuracy %>%
rename(roc.auc = roc_auc) %>%
select(-partition) %>%
summarize_all(.funs = list(mean = mean, sd = sd)) %>%
gather() %>%
separate(key, into = c('metric', 'stat'), sep = '_') %>%
spread(stat, value)
left_join(train_summaries,
test_summaries,
by = 'metric',
suffix = c('.train', '.test')) %>%
select(metric, contains('mean'), contains('sd')) %>%
knitr::kable()
url <- 'https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/scripts/package-installs.R'
source(url)
